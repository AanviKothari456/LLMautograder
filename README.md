# ğŸ¤– LLM Autograder
A full-stack application that tests the coding capabilities of an LLM. It randomly selects a coding question, has an LLM generate a solution and test cases (without seeing the solution during test generation), and evaluates the correctness using a secure sandbox.

## ğŸ§© Features
- Random LeetCode-style question selection
- Code and unit test generation by LLM (OpenAI GPT-4)
- Mocha-style JS test evaluation using `vm2`
- React.js frontend for interactive usage

## ğŸ“ Project Structure
```
LLMautograder/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ controllers/         # API logic
â”‚   â”œâ”€â”€ services/            # LLM + test runner logic
â”‚   â”œâ”€â”€ routes/              # Express routes
â”‚   â”œâ”€â”€ data/                # LeetCode-like question bank
â”‚   â””â”€â”€ app.js               # Server entry
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ components/      # React UI components
â”‚       â”œâ”€â”€ App.jsx
â”‚       â”œâ”€â”€ index.js
â”‚       â””â”€â”€ api.js
â”œâ”€â”€ .env                     # Environment variables
â””â”€â”€ README.md
```

## ğŸš€ Getting Started
### 1. Clone the Repo
```bash
git clone https://github.com/AanviKothari456/LLMautograder.git
cd LLMautograder
```

### 2. Setup Backend
```bash
cd backend
npm install
```
Create a `.env` file:
```
PORT=5000
OPENAI_API_KEY=your_openai_api_key_here
```
Then run:
```bash
node app.js
```

### 3. Setup Frontend
```bash
cd ../frontend
npm install
npm start
```

Frontend will run on `http://localhost:3000` and connect to `localhost:5000` backend.

## ğŸ” Security Notes
- All code execution is sandboxed using `vm2` to prevent unsafe eval.
- The test generator never sees the solution â€” test independence is enforced by design.

## ğŸ“Œ Future Improvements
- Multi-language support (Python, Java, etc.)
- Docker-based secure execution environments
- LLM benchmark tracking over time

## ğŸ§  Powered By
- OpenAI GPT-4
- React.js + Express.js
- vm2 sandbox for secure code evaluation
